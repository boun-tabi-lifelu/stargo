{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYNcgUs348V"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sBRXVTd348W",
        "outputId": "e42d02ec-e1f5-4b15-930d-e69b01d7d016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Mounted at /content/drive\n",
            "Cloning into 'contempro'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 364 (delta 186), reused 291 (delta 116), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (364/364), 6.61 MiB | 13.29 MiB/s, done.\n",
            "Resolving deltas: 100% (186/186), done.\n",
            "/content/contempro/work\n"
          ]
        }
      ],
      "source": [
        "#@title Dependencies and Imports\n",
        "from google.colab import userdata, drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#@title Environment Variables\n",
        "github_pat = userdata.get(\"GITHUB_PAT\")\n",
        "wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%pip install -q lightning click transformers goatools toml wget fastobo pydantic loguru obonet\n",
        "\n",
        "\n",
        "#@title Clone and cd\n",
        "if os.getcwd() != \"/content/contempro/work\":\n",
        "  if not Path(\"/content/contempro\").exists():\n",
        "    !git clone https://{github_pat}@github.com/boun-tabi-lifelu/contempro.git\n",
        "  %cd /content/contempro/work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftnjvS82_Nyn",
        "outputId": "544da391-0f85-4d02-b00d-8bf5d15fd71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  work-pfresgo-data.zip\n",
            "   creating: pfresgo/\n",
            "  inflating: __MACOSX/._pfresgo      \n",
            "  inflating: pfresgo/.DS_Store       \n",
            "  inflating: __MACOSX/pfresgo/._.DS_Store  \n",
            "  inflating: pfresgo/annot.tsv       \n",
            "  inflating: __MACOSX/pfresgo/._annot.tsv  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: pfresgo/train.txt       \n",
            "  inflating: __MACOSX/pfresgo/._train.txt  \n",
            "  inflating: pfresgo/go.obo          \n",
            "  inflating: __MACOSX/pfresgo/._go.obo  \n",
            "  inflating: pfresgo/ontology.embeddings.npy  \n",
            "  inflating: __MACOSX/pfresgo/._ontology.embeddings.npy  \n",
            "  inflating: pfresgo/valid.txt       \n",
            "  inflating: __MACOSX/pfresgo/._valid.txt  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: pfresgo/test.txt        \n",
            "  inflating: __MACOSX/pfresgo/._test.txt  \n"
          ]
        }
      ],
      "source": [
        "#@title Setup data\n",
        "!mkdir -p datasets\n",
        "!cp /content/drive/MyDrive/research/contempro/work-pfresgo-data.zip ./datasets\n",
        "!cd datasets && unzip -o work-pfresgo-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eIrB7V4X_O_-"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/research/per_residue_embeddings.h5 ./datasets/pfresgo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azDyNczt348X"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run bin/evaluate.py --config_file configs/ordered_encdec_medium.toml --go_release 2024 --subontology biological_process --use_wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bWTYl5pI348X"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "import torch\n",
        "from model import TrainingModel, get_model_cls\n",
        "from config import from_toml\n",
        "from pathlib import Path\n",
        "from data.datamodule import PFresGODataModule\n",
        "from torch.nn.functional import sigmoid\n",
        "import os\n",
        "\n",
        "subontology = \"biological_process\" # @param {type:\"string\"}\n",
        "config_file = \"configs/ordered_encdec_medium.toml\" #@param {type:\"string\"}\n",
        "go_release = \"2024\" #@param [\"2020\", \"2024\"]\n",
        "use_wandb = True #@param {type:\"boolean\"}\n",
        "\n",
        "model_type = config_file.split(\"/\")[-1].split(\".\")[0].replace(\"_\", \"-\")\n",
        "subontology_short = ''.join([word[0] for word in subontology.split(\"_\")])\n",
        "model_name = f\"contempro-{subontology_short}-{go_release}-{model_type}\"\n",
        "\n",
        "config = from_toml(config_file)\n",
        "\n",
        "data_root_dir = Path(config.train.data_dir)\n",
        "\n",
        "def load_model(ontology: Literal[\"molecular_function\", \"biological_process\", \"cellular_component\"]):\n",
        "  subontology = ontology\n",
        "  subontology_short = ''.join([word[0] for word in subontology.split(\"_\")])\n",
        "\n",
        "  config.train.subontology = subontology # override subontology\n",
        "\n",
        "  model_name = f\"contempro-{subontology_short}-{go_release}-{model_type}\"\n",
        "\n",
        "  if use_wandb:\n",
        "    import wandb\n",
        "    run = wandb.init(project=\"contempro\", name=model_name+\"-eval\", job_type=\"eval\")\n",
        "    wandb.config.update(config)\n",
        "    wandb.config.update({\"model_name\": model_name})\n",
        "    wandb.config.update({\"subontology\": subontology})\n",
        "    artifact = run.use_artifact(f\"{model_name}:latest\")\n",
        "    os.makedirs(\"trained_models\", exist_ok=True)\n",
        "    path = artifact.download(root=\"trained_models\")\n",
        "    print(path)\n",
        "    model = get_model_cls(config.model.name)(config.model)\n",
        "    module = TrainingModel.load_from_checkpoint(\n",
        "      \"trained_models/\"+artifact.files()[0].name,\n",
        "      model=model,\n",
        "      training_config=config.train\n",
        "    )\n",
        "  else:\n",
        "    module = TrainingModel.load_from_checkpoint(f\"trained_models/{model_name}.ckpt\", model=model, training_config=config.train)\n",
        "\n",
        "  return module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0Bkf3D0R348Y"
      },
      "outputs": [],
      "source": [
        "#@title Load Data\n",
        "\n",
        "dm = PFresGODataModule(\n",
        "  data_dir=data_root_dir,\n",
        "  batch_size=32,\n",
        "  num_workers=config.train.dm_num_workers,\n",
        "  ontology=subontology,\n",
        "  order_go_terms=config.train.order_go_terms,\n",
        "  go_release=go_release,\n",
        ")\n",
        "dm.setup(\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JArz8shy348Y",
        "outputId": "5111a277-caab-4705-9bd6-72c33aed3fc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 107/107 [46:21<00:00, 26.00s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title Inference\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = load_model(subontology)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    batches_list = []\n",
        "\n",
        "    for batch in tqdm(dm.test_dataloader()):\n",
        "        result = sigmoid(model({\n",
        "            \"embeddings\": batch[\"embeddings\"].cuda(),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].cuda(),\n",
        "            \"go_embeddings\": batch[\"go_embeddings\"].cuda()\n",
        "        }))\n",
        "        batches_list.append(result)\n",
        "\n",
        "    result = torch.cat(batches_list, dim=0)\n",
        "\n",
        "\n",
        "torch.save(result, f\"{model_name}_test_preds.pt\")\n",
        "if use_wandb:\n",
        "    import wandb\n",
        "    art = wandb.Artifact(model_name, type=\"predictions\").add_file(f\"{model_name}_test_preds.pt\")\n",
        "    wandb.log_artifact(art)\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxJgjFYT348Y"
      },
      "source": [
        "## PFresGO Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtrxKLnS348Y",
        "outputId": "f3096fb4-0d7d-420c-add3-3f0cc36f0538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from data.datamodule import PFresGODataModule\n",
        "from pfresgo_eval import Method, load_test_prots, protein_centric_aupr_curves\n",
        "\n",
        "if use_wandb:\n",
        "  wandb.init(project=\"contempro\", name=model_name+\"-eval-metrics\", job_type=\"eval\")\n",
        "# Configuration\n",
        "predictions_file = f\"{model_name}_test_preds.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfMsWNuL348Y",
        "outputId": "812b4263-de23-4e96-a8bd-00a708e744ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions shape: torch.Size([3416, 30735])\n",
            "Number of test samples: 3416\n",
            "Number of GO terms: 30735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-7a7d7f04c319>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_preds = torch.load(predictions_file, map_location='cpu')\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load Data\n",
        "# Initialize and setup datamodule\n",
        "dm.setup(\"test\")\n",
        "\n",
        "# Load predictions\n",
        "test_preds = torch.load(predictions_file, map_location='cpu')\n",
        "print(f\"Predictions shape: {test_preds.shape}\")\n",
        "print(f\"Number of test samples: {len(dm.test_dataset)}\")\n",
        "print(f\"Number of GO terms: {len(dm.test_dataset.go_term_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "liLanuuX348Y"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Prepare Evaluation Data\n",
        "all_annots = []\n",
        "for batch in dm.test_dataloader():\n",
        "    all_annots.append(batch[\"annotations\"])\n",
        "\n",
        "all_annots = torch.cat(all_annots, dim=0)\n",
        "\n",
        "eval_data = {\n",
        "    'Y_true': all_annots.cpu().numpy(),\n",
        "    'Y_pred': test_preds.cpu().numpy(),\n",
        "    'goterms': dm.test_dataset.go_term_list,\n",
        "    'proteins': dm.test_dataset.protein_ids\n",
        "}\n",
        "\n",
        "# Save evaluation data\n",
        "with open('eval_results.pckl', 'wb') as f:\n",
        "    pickle.dump(eval_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDuS_KLz348Y",
        "outputId": "1e36d8c4-0260-4611-af94-2c3d1ca5d59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Number of functions =1907\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Create Method Object and Calculate Metrics\n",
        "# Create evaluation method\n",
        "method = Method('Contempro', 'eval_results.pckl', subontology_short)\n",
        "\n",
        "# Load test protein indices\n",
        "test_prots, seqid_mtrx = load_test_prots('./datasets/pfresgo/nrPDB-GO_2019.06.18_test.csv')\n",
        "prot_idx = np.where(seqid_mtrx[:, 4] == 1)[0]\n",
        "\n",
        "# Calculate metrics\n",
        "micro_aupr, macro_aupr, _ = method._function_centric_aupr(keep_pidx=prot_idx)\n",
        "auc = method.AUC(keep_pidx=prot_idx)\n",
        "fmax = method.fmax(keep_pidx=prot_idx)\n",
        "\n",
        "# Print results\n",
        "results = {\n",
        "    \"Micro AUPR\": micro_aupr,\n",
        "    \"Macro AUPR\": macro_aupr,\n",
        "    \"AUC\": auc,\n",
        "    \"Fmax\": fmax\n",
        "}\n",
        "\n",
        "for metric, value in results.items():\n",
        "    print(f\"{metric}: {value:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k75ImHIE348Z"
      },
      "outputs": [],
      "source": [
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYB6Og_I348Z"
      },
      "outputs": [],
      "source": [
        "#@title Save metrics to JSON\n",
        "import json\n",
        "results[\"model\"] = model_name\n",
        "results = {k: float(v) if type(v) != str else v for k, v in results.items()}  # Convert numpy types to native Python types\n",
        "\n",
        "with open(f\"{model_name}_metrics.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)  # Added indent for better readability\n",
        "if use_wandb:\n",
        "    wandb.log(results)\n",
        "    wandb.finish()\n",
        "\n",
        "print(f\"Metrics saved to {model_name}_metrics.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGWM7KDnK9mY"
      },
      "outputs": [],
      "source": [
        "!cp {model_name}_metrics.json /content/drive/MyDrive/research/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
